{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"controller_device_3.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1JtVjXmQ_TYLEOHRIQOanP1KHGG22WLUR","authorship_tag":"ABX9TyMnXc65N/FauorHHnTZju2y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"glG8cvK4MvtC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621968178448,"user_tz":420,"elapsed":3113,"user":{"displayName":"Aditya Mamidi","photoUrl":"https://lh3.googleusercontent.com/-ZVjFvZzfSRk/AAAAAAAAAAI/AAAAAAAAO_o/YuKurwGqPLs/s64/photo.jpg","userId":"11230502904851788584"}},"outputId":"7e2abc2b-9a68-4200-b7b9-ef6747d11d3e"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)\n","# !pip install networkx==1.11\n","# import networkx as nx"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5HYxeHZ-M5Ro"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ePzdLZRM7Rc"},"source":["from multiprocessing import Pool\n","from multiprocessing.pool import ThreadPool\n","import math\n","import random\n","import numpy as np\n","import six\n","import json\n","import os\n","import re\n","import sys\n","from subprocess import call, Popen, PIPE\n","import subprocess\n","from time import gmtime, strftime\n","import time\n","import pickle\n","import os\n","import tensorflow as tf\n","from tensorflow.python.ops import tensor_array_ops"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xyNSXMRjf-1","executionInfo":{"status":"ok","timestamp":1621930322351,"user_tz":420,"elapsed":832,"user":{"displayName":"Aditya Mamidi","photoUrl":"https://lh3.googleusercontent.com/-ZVjFvZzfSRk/AAAAAAAAAAI/AAAAAAAAO_o/YuKurwGqPLs/s64/photo.jpg","userId":"11230502904851788584"}},"outputId":"47eedfe7-301c-4ae0-9217-6a5cd49a54a7"},"source":["%cd /content/drive/MyDrive/Classwork/CSE_257/DREAM/\n","# import replay_buffer\n","from environment import Environment, Sample"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Classwork/CSE_257/DREAM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HYMs_Cvejf-1"},"source":["from graphsage.utils import load_ordered_folder_data\n","from graphsage.minibatch_eval import GraphMinibatchIterator\n","from graphsage.neigh_samplers import UniformNeighborSampler\n","from graphsage.models import SAGEInfo\n","from graphsage.supervised_models import SupervisedGraphsage"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQQuFXepjf-1"},"source":["class PlacerParams(object):\n","  def __init__(self, **kwargs):\n","    for name, value in six.iteritems(kwargs):\n","      self.add_param(name, value)\n","\n","  def add_param(self, name, value):\n","    setattr(self, name, value)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JgC571Bmjf-2"},"source":["def allocator_hparams():\n","  \"\"\"Hyperparameters for resource allocator.\"\"\"\n","  return PlacerParams(\n","      hidden_size=512,\n","      forget_bias_init=1.0,\n","      grad_bound=1.0,\n","      lr=0.01,\n","      lr_dec=1.0,\n","      decay_steps=50,\n","      start_decay_step=400,\n","      optimizer_type=\"adam\",\n","      name=\"hierarchical_controller\",\n","      keep_prob=1.0,\n","      seed=1,\n","      model_size = 'small', \n","      random_prob = 1.0,\n","      max_degree = 100,\n","      epoches = 10000, \n","      dropout = 0.0, \n","      n_explore_samples = 20,\n","      n_replay_samples = 5,\n","      replay_greedy_sampling = True,\n","      n_policy_samples = 10,\n","      train_ratio = 0.8, \n","      restore = False,\n","      checkpoint = True,\n","      checkpoint_folder = 'checkpoints',\n","      cep_program = 'LogProcessing',\n","      graphsage_model = 'graphsage_maxpool', \n","      samples_1 = 4,\n","      samples_2 = 4,\n","      samples_3 = 0,\n","      samples_4 = 0,\n","      samples_5 = 0,\n","      dim_1 = 128,\n","      dim_2 = 128,\n","      strategy = 'policy', # or memory\n","      replay_weight = 10.0, \n","      env_batch_size = 1, # number of env in a batch\n","      embedding = 'graphsage', #original or use graphsage\n","      feat_size = 1, #only valid if embedding is original\n","      decoder = 'lstm', # only lstm is supported\n","      placement_file = 'tmp.json',\n","      consider_neighbor_placement = False, #whether to consider the placement of neighbor nodes\n","      consider_device_utilization = False,\n","      weighed_neighbor_placement = True, #only useful if consider_neighbor_placement is True\n","      utilization_max = 2.0,\n","      device_scheme = 0,\n","      real_baseline = True,\n","      pool_size = 5,\n","      num_devices = 5,\n","      metis_placement = None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NrvKMLqojf-2"},"source":["class Task(object):\n","  def __init__(self, num_ops, graph_idx, action, device_utilizations, is_policy, placement_file, cep_program, exp_folder):\n","    self.num_ops = num_ops\n","    self.graph_idx = graph_idx\n","    self.action = action\n","    self.device_utilizations = device_utilizations\n","    self.is_policy = is_policy\n","    self.placement_file = placement_file\n","    self.cep_program = cep_program\n","    self.exp_folder = exp_folder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQ16hMdcjf-2"},"source":["def evaluate(t):\n","  action = t.action\n","  num_ops = t.num_ops\n","  graph_idx = t.graph_idx\n","  device_utilizations = t.device_utilizations\n","  is_policy = t.is_policy\n","  placement_file = t.placement_file\n","  cep_program = t.cep_program\n","  exp_folder = t.exp_folder\n","  \n","  configs = {}\n","  placements = []\n","  vm_placements = {}\n","  for i in range(num_ops):\n","    vm = int(action[i])\n","    if vm not in vm_placements:\n","      vm_placements[vm] = []\n","    vm_placements[vm].append(int(i))\n","  for vm, ops in vm_placements.items():\n","    placements.append({'idx':vm, 'ops': ops})\n","  configs['placements'] = placements\n","  \n","  used_vms = len(vm_placements)\n","  with open(placement_file, 'w') as outfile:\n","    json.dump(configs, outfile)\n","  \n","  seq = ['timeout', '-k','30s','-s', '9', '30s','java', 'ca.uwo.eng.sel.cepsim.example.'+cep_program, placement_file, exp_folder+'/graph_'+str(graph_idx)+'.json']\n","  p = Popen(seq, stdout=PIPE, stderr=PIPE)\n","  stdout, stderr = p.communicate()\n","  logs = stdout\n","  throughput = 0\n","  for line in logs.split(b'\\n'):\n","    if b\"Throughputs:\" in line:\n","      throughput += float(line.strip().split(b':')[1])\n","  throughput/=used_vms\n","  s = Sample(action, throughput, device_utilizations, is_policy = is_policy)\n","  return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KuaFGkmojf--"},"source":["def lstm(x, prev_c, prev_h, w_lstm, forget_bias):\n","  ifog = tf.matmul(tf.concat([x, prev_h], axis=1), w_lstm)\n","  i, f, o, g = tf.split(ifog, 4, axis=1)\n","  i = tf.sigmoid(i)\n","  f = tf.sigmoid(f + forget_bias)\n","  o = tf.sigmoid(o)\n","  g = tf.tanh(g)\n","  next_c = i * g + f * prev_c\n","  next_h = o * tf.tanh(next_c)\n","  return next_c, next_h"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJ021wusjf-3"},"source":["class ResourceAllocator():\n","  \"\"\"ResourceAllocator class.\"\"\"\n","  def get_time(self):\n","    return strftime(\"%Y-%m-%d-%H:%M:%S\", gmtime())\n","\n","  def __init__(self, hparams, exp_folder, restore_file=0):\n","    \"\"\"ResourceAllocator class initializer.\n","\n","    Args:\n","      hparams: All hyper-parameters.\n","      exp_folder: The folder contains the dataset.\n","    \"\"\"\n","    self.hparams = hparams\n","    self.exp_folder = exp_folder\n","    \n","    self.construct_placeholders()\n","    \n","    #graph minibatch iterator \n","    self.prepare_data()\n","    \n","    #build graph model\n","    if self.hparams.embedding == 'graphsage':\n","      self.build_graph_model()\n","    \n","    self.init_variables()\n","    \n","    #build sample generation \n","    self.build_generate_samples()\n","    \n","    self.build_controller()  \n","    \n","    self.init()\n","    \n","    if self.hparams.restore:\n","      with open(self.hparams.env_restore_file, 'rb') as f:\n","        self.envs = pickle.load(f)\n","    else:  \n","      self.envs = {}\n","    \n","    self.ignored_samples = 0\n","    self.total_samples = 0\n","    \n","    self.train()\n","  \n","  def load_metis_samples(self, g_idx, batch_size, batch_loads):\n","    filename = str(g_idx) + \".json\"\n","    G_data = json.load(open(os.path.join('metis_placement', filename)))\n","    p = G_data['placements']\n","    placement = {}\n","    for one_vm in p:\n","      vm_idx = int(one_vm['idx'])\n","      ops = one_vm['ops']\n","      for op in ops:\n","        op = int(op)\n","        placement[op] = vm_idx\n","    action = []\n","    for op in range(len(placement)):\n","      action.append(placement[op])\n","    action = self.uniform_action(batch_size, action)\n","    device_utilization = self.calculate_utilization(action, batch_loads)\n","    return action, device_utilization\n","  \n","  def init_variables(self):\n","    self.initializer = tf.glorot_uniform_initializer(seed=self.hparams.seed)\n","    with tf.variable_scope(\n","        self.hparams.name,\n","        initializer=self.initializer,\n","        reuse=tf.AUTO_REUSE):\n","      if self.hparams.decoder == 'lstm':\n","        if self.hparams.embedding == 'graphsage':\n","          tf.get_variable(\"device_softmax\", [2 * self.hparams.hidden_size, self.num_devices]) #with attention\n","          tf.get_variable(\"device_embeddings\", [self.num_devices, self.hparams.hidden_size])\n","          tf.get_variable(\"device_go_embedding\", [1, self.hparams.hidden_size])\n","          tf.get_variable(\"attn_w_2\", [self.hparams.hidden_size, self.hparams.hidden_size])\n","          tf.get_variable(\"attn_v\", [self.hparams.hidden_size, 1])\n","          if self.hparams.consider_neighbor_placement and self.hparams.consider_device_utilization:\n","            w_lstm_dimension = 3 * self.hparams.hidden_size\n","          elif self.hparams.consider_device_utilization or self.hparams.consider_neighbor_placement:\n","            w_lstm_dimension = 3 * self.hparams.hidden_size\n","          else:  \n","            w_lstm_dimension = 2 * self.hparams.hidden_size\n","        elif self.hparams.embedding == 'original': #original embedding\n","          if self.hparams.consider_neighbor_placement and self.hparams.consider_device_utilization:\n","            w_lstm_dimension = 3 * self.hparams.hidden_size\n","          elif self.hparams.consider_device_utilization or self.hparams.consider_neighbor_placement:\n","            w_lstm_dimension = 3 * self.hparams.hidden_size\n","          else:  \n","            w_lstm_dimension = 2 * self.hparams.hidden_size\n","          tf.get_variable(\"device_softmax\", [self.hparams.hidden_size, self.num_devices])\n","          tf.get_variable(\"node_embedding\", [self.hparams.feat_size, self.hparams.hidden_size])\n","        else:\n","          raise NotImplementedError\n","        tf.get_variable(\"decoder_lstm\", [w_lstm_dimension, 4 * self.hparams.hidden_size])\n","        tf.get_variable(\"device_aggregator\", [self.num_devices, self.hparams.hidden_size])\n","        tf.get_variable(\"decoder_forget_bias\", shape=1, dtype=tf.float32, initializer=tf.constant_initializer( self.hparams.forget_bias_init))\n","        if self.hparams.consider_device_utilization:\n","          tf.get_variable(\"device_utilization\", [2*self.num_devices, self.num_devices])\n","      device_indices = []\n","      for i in range(self.num_devices):\n","        device_indices.append(i)\n","      self.device_encoding = tf.one_hot(device_indices, self.num_devices)  \n","  \n","  def init(self):\n","    self.sess = tf.Session()\n","\n","    if self.hparams.restore:\n","      self.saver = tf.train.Saver()\n","      self.saver.restore(self.sess, self.hparams.model_restore_file)\n","    else:  \n","      init_g = tf.global_variables_initializer() \n","      init_l = tf.local_variables_initializer()\n","      self.saver = tf.train.Saver()\n","      self.sess.run([init_g, init_l])\n","  \n","  def get_random_action(self, batch_size, feed_dict, batch_loads):\n","    a = random.randint(0, math.pow(self.num_devices, batch_size) - 1)\n","    action = []\n","    for op in range(batch_size):\n","      action.append(a%self.num_devices)\n","      a = a/self.num_devices\n","    action = self.uniform_action(batch_size, action)\n","    device_utilization_backward = self.calculate_utilization(action, batch_loads)\n","    return action, device_utilization_backward\n","  \n","  def get_sample_action(self, sample_size, batch_size, feed_dict, batch_loads, batch_sources, batch_num_sources, batch_source_weights, mode='sample'):\n","    num_children = sample_size\n","    feed_dict.update({self.placeholders['sample_size']:sample_size})\n","    feed_dict.update({self.placeholders['num_samples']:sample_size})\n","    device_utilization = np.zeros((num_children, self.num_devices), dtype=float) \n","    prev_c = np.zeros((num_children, self.hparams.hidden_size), dtype=float)\n","    prev_h = np.zeros((num_children, self.hparams.hidden_size), dtype=float)\n","    prev_y = np.zeros((num_children), dtype=float)\n","    \n","    for i in range(num_children):\n","      for j in range(self.num_devices):\n","        device_utilization[i, j] = self.hparams.utilization_max\n","    \n","    action = [None] * sample_size\n","    for i in range(sample_size):\n","      action[i] = []\n","\n","    for op in range(batch_size):\n","      feed_dict.update({self.placeholders['target_op']:op})\n","      feed_dict.update({self.placeholders['prev_c']:prev_c})\n","      feed_dict.update({self.placeholders['prev_h']:prev_h})\n","      feed_dict.update({self.placeholders['prev_y']:prev_y})\n","      feed_dict.update({self.placeholders['device_utilizations_forward']:device_utilization})\n","      if self.hparams.consider_neighbor_placement:\n","        source_weights = []\n","        source_devices = []\n","        for j in range(sample_size):\n","          source_devices.append([])\n","        node_sources_num = batch_num_sources[op]\n","        for i in range(node_sources_num):\n","          source_weights.append(batch_source_weights[op, i])\n","        for j in range(sample_size):\n","          for i in range(node_sources_num):\n","            source = batch_sources[op, i]\n","            source_devices[j].append(action[j][source])\n","        feed_dict.update({self.placeholders['source_weights']:source_weights})\n","        feed_dict.update({self.placeholders['source_devices']:source_devices})\n","        feed_dict.update({self.placeholders['node_sources_num']:node_sources_num})\n","        \n","      if mode == 'sample':\n","        prev_y, prev_c, prev_h = self.sess.run([self.policy_action, self.policy_c, self.policy_h], feed_dict=feed_dict)\n","      elif mode == 'greedy':  \n","        prev_y, prev_c, prev_h = self.sess.run([self.greedy_action, self.greedy_c, self.greedy_h], feed_dict=feed_dict)\n","      else:\n","        raise NotImplementedError\n","      for i in range(sample_size):\n","        action[i].append(prev_y[i])\n","        load = batch_loads[op]/1e6\n","        device_utilization[i, action[i][op]] -= load\n","    \n","    uniform_actions = []\n","    device_utilization_backward = []\n","    for i in range(sample_size):\n","      a = self.uniform_action(batch_size, action[i])\n","      uniform_actions.append(a)\n","      device_utilization_backward.append(self.calculate_utilization(a, batch_loads))\n","    return uniform_actions, device_utilization_backward\n","\n","  def get_action(self, batch_size, feed_dict, batch_loads, batch_sources, batch_num_sources, batch_source_weights, mode='sample'):\n","    num_children = 1\n","    feed_dict.update({self.placeholders['num_samples']:1})\n","    device_utilization = np.zeros((num_children, self.num_devices), dtype=float) \n","    prev_c = np.zeros((num_children, self.hparams.hidden_size), dtype=float)\n","    prev_h = np.zeros((num_children, self.hparams.hidden_size), dtype=float)\n","    prev_y = np.zeros((num_children), dtype=float)\n","    \n","    for i in range(num_children):\n","      for j in range(self.num_devices):\n","        device_utilization[i, j] = self.hparams.utilization_max\n","    \n","    action = []\n","    for op in range(batch_size):\n","      feed_dict.update({self.placeholders['target_op']:op})\n","      feed_dict.update({self.placeholders['prev_c']:prev_c})\n","      feed_dict.update({self.placeholders['prev_h']:prev_h})\n","      feed_dict.update({self.placeholders['prev_y']:prev_y})\n","      feed_dict.update({self.placeholders['device_utilizations_forward']:device_utilization})\n","      if self.hparams.consider_neighbor_placement:\n","        source_weights = []\n","        source_devices = []\n","        for j in range(1):\n","          source_devices.append([])\n","        node_sources_num = batch_num_sources[op]\n","        for i in range(node_sources_num):\n","          source_weights.append(batch_source_weights[op, i])\n","        for j in range(1):\n","          for i in range(node_sources_num):\n","            source = batch_sources[op, i]\n","            source_devices[j].append(action[source])\n","        feed_dict.update({self.placeholders['source_weights']:source_weights})\n","        feed_dict.update({self.placeholders['source_devices']:source_devices})\n","        feed_dict.update({self.placeholders['node_sources_num']:node_sources_num})\n","        \n","      if mode == 'sample':\n","        prev_y, prev_c, prev_h = self.sess.run([self.policy_action, self.policy_c, self.policy_h], feed_dict=feed_dict)\n","      elif mode == 'greedy':  \n","        prev_y, prev_c, prev_h = self.sess.run([self.greedy_action, self.greedy_c, self.greedy_h], feed_dict=feed_dict)\n","      else:\n","        raise NotImplementedError\n","      action.append(prev_y[0])\n","      load = batch_loads[op]/1e6\n","      device_utilization[0, action[op]] -= load\n","    \n","    action = self.uniform_action(batch_size, action)\n","    device_utilization_backward = self.calculate_utilization(action, batch_loads)\n","    return action, device_utilization_backward\n","  \n","  def get_sample(self, batch_size, real_idx, action, device_utilization, g_idx = -1):\n","    action_str = ''.join(str(i) for i in action)\n","    s=None\n","    if g_idx !=-1:\n","      throughput = self.envs[g_idx].if_exist(action_str)\n","      if throughput == -1:\n","        throughput = self.evaluate_cepsim(batch_size, real_idx, action)\n","    else: \n","      throughput = self.evaluate_cepsim(batch_size, real_idx, action)\n","    if throughput > 0:\n","      s = Sample(action, throughput, device_utilization)\n","    return s\n","\n","  def prepare_samples_for_back(self, fd, train_samples, epoch, num_replay_samples):  \n","    if len(train_samples) == 0:\n","      return None\n","    actions = np.vstack([s.action for s in train_samples])\n","    ranks = [s.rank for s in train_samples]\n","    utilizations = [s.device_utilization for s in train_samples]\n","    utilizations = np.concatenate(utilizations, axis=1)\n","    fd['device_utilizations'] = utilizations\n","    if self.hparams.real_baseline == True:\n","      baseline = self.envs[fd['graph_idx']].calculate_baseline(epoch, num_replay_samples)\n","    else:\n","      baseline = np.mean(ranks)\n","    \n","    probs = self.compute_probs(actions, actions.shape[0], fd)\n","    for idx, r in enumerate(ranks):\n","      r_origin = r\n","      r -= baseline\n","      ranks[idx] = r\n","      p  = probs[idx]\n","      if p == 0.0 and r < 0: #if negative sample and probability is already small, ignore it\n","        ranks[idx] = 0\n","        self.ignored_samples += 1\n","      else:\n","        self.total_samples += 1\n","      if r > 0:\n","        ranks[idx] = self.hparams.replay_weight * r\n","    \n","    train_ranks = np.array(ranks)\n","    fd['num_actions'] = len(train_samples)\n","    fd['actions'] = actions\n","    fd['reward'] = train_ranks\n","    return fd\n","\n","  def train(self):\n","    for epoch in range(self.hparams.epoches):\n","      epoch_start_time = time.time()\n","      self.minibatch.shuffle()\n","      print(\"start epoch {} {}\".format(epoch, epoch_start_time))\n","      self.ignored_samples = 0\n","      self.total_samples = 0\n","      while not self.minibatch.end():\n","        one_start_time = time.time()\n","        dict_for_back = {}\n","        graph_batch_size = self.minibatch.next_batch_size()\n","        for local_idx in range(graph_batch_size):\n","          feed_dict, batch, batch_loads, batch_size, batch_sources, batch_source_weights, num_batch_sources, graph_idx, real_idx, max_throughput = self.minibatch.next_minibatch_feed_dict()\n","          feed_dict.update({self.placeholders['dropout']: self.hparams.dropout})\n","          feed_dict.update({self.placeholders['sample_size']: 1})\n","          fd = {'batch_size': batch_size, 'batch' : batch, 'batch_sources' : batch_sources, 'batch_num_sources':num_batch_sources, 'graph_idx': graph_idx, 'batch_source_weights' : batch_source_weights}\n","          \n","          if graph_idx not in self.envs:\n","            self.envs[graph_idx] = Environment(graph_idx, batch_size, max_throughput, queue_leangth = 30)\n","          \n","          if self.hparams.strategy == 'policy':\n","            for _ in range(self.hparams.n_policy_samples):\n","              if np.random.rand() < self.hparams.random_prob/np.exp(epoch):\n","                action, device_utilization = self.get_random_action(batch_size, feed_dict, batch_loads)\n","              else:\n","                action, device_utilization = self.get_action(batch_size, feed_dict, batch_loads, batch_sources, num_batch_sources, batch_source_weights, mode = 'sample')\n","              \n","              s = self.get_sample(batch_size, real_idx, action, device_utilization, g_idx=graph_idx)\n","              if s != None:\n","                self.envs[graph_idx].save(s, on_policy=True, build_replay=False)\n","              \n","            policy_samples = self.envs[graph_idx].sample(self.hparams.n_policy_samples) \n","            \n","          elif self.hparams.strategy == 'memory':\n","            random_prob = self.hparams.random_prob/np.exp(epoch)\n","            num_random_samples = (int)(self.hparams.n_explore_samples * random_prob)\n","            if self.envs[graph_idx].hard_problem():\n","              num_random_samples = self.hparams.n_explore_samples \n","            tasks = []\n","            random_set = set()\n","            for _ in range(num_random_samples): \n","              action, device_utilization = self.get_random_action(batch_size, feed_dict, batch_loads)\n","              action_str = ''.join(str(i) for i in action)\n","              if action_str not in random_set:\n","                random_set.add(action_str)\n","                throughput = self.envs[graph_idx].if_exist(action_str) \n","                if throughput != -1:\n","                  s = Sample(action, throughput, device_utilization)\n","                  self.envs[graph_idx].save(s)\n","                else:\n","                  t = Task(batch_size, real_idx, action, device_utilization, False, self.hparams.placement_file+'_'+str(len(tasks))+'.json', self.hparams.cep_program, self.exp_folder)\n","                  tasks.append(t)\n","            #load metis placement\n","            if epoch == 0 and self.hparams.metis_placement != None:\n","              action, device_utilization = self.load_metis_samples(real_idx, batch_size, batch_loads)\n","              t = Task(batch_size, real_idx, action, device_utilization, False, self.hparams.placement_file+'_'+str(len(tasks))+'.json', self.hparams.cep_program, self.exp_folder)\n","              tasks.append(t)\n","            policy_samples = []\n","            policy_set = set()\n","            start_policy_time = time.time();\n","            actions, device_utilizations = self.get_sample_action(self.hparams.n_policy_samples, batch_size, feed_dict, batch_loads, batch_sources, num_batch_sources, batch_source_weights, mode = 'sample')\n","            for p in range(self.hparams.n_policy_samples): \n","              action_str = ''.join(str(i) for i in actions[p])\n","              if action_str not in policy_set:\n","                policy_set.add(action_str)\n","                throughput = self.envs[graph_idx].if_exist(action_str)\n","                if throughput == -1:\n","                  t = Task(batch_size, real_idx, actions[p], device_utilizations[p], True, self.hparams.placement_file+'_'+str(len(tasks))+'.json', self.hparams.cep_program, self.exp_folder)\n","                  tasks.append(t)\n","                else:\n","                  s = Sample(actions[p], throughput, device_utilizations[p])\n","                  self.envs[graph_idx].save(s, on_policy = True)\n","                  policy_samples.append(s)\n","            \n","            \n","            start_time = time.time()\n","            with ThreadPool(min(10, max(self.hparams.pool_size, len(tasks)))) as p:\n","              pending_samples = p.map(evaluate, tasks)\n","              for s in pending_samples:\n","                if s.is_policy:\n","                  self.envs[graph_idx].save(s, on_policy = True)\n","                  policy_samples.append(s)\n","                else:\n","                  self.envs[graph_idx].save(s)\n","\n","            replay_samples = self.envs[graph_idx].replay(self.hparams.n_replay_samples, greedy = self.hparams.replay_greedy_sampling)\n","            train_samples = replay_samples + policy_samples\n","            \n","            dict_for_back = self.prepare_samples_for_back(fd, train_samples, epoch, len(replay_samples))\n","          else:    \n","            raise NotImplementedError\n","        if dict_for_back != None:\n","          self.optimize(dict_for_back)\n","      \n","      start_time = time.time()\n","      self.test_w_throughput()\n","      \n","      if self.hparams.checkpoint and epoch % 10 == 0:\n","        self.save(epoch)\n","  \n","  def test_w_throughput(self):\n","    tasks = []\n","    while not self.minibatch.eval_end():\n","      feed_dict, batch, batch_loads, batch_size, batch_sources, batch_source_weights, num_batch_sources, graph_idx, real_idx, max_throughput = self.minibatch.next_eval_minibatch_feed_dict()\n","      if graph_idx not in self.envs:\n","        self.envs[graph_idx] = Environment(graph_idx, batch_size, max_throughput)\n","\n","      feed_dict.update({self.placeholders['dropout']: self.hparams.dropout})\n","      feed_dict.update({self.placeholders['sample_size']: 1})\n","      action, _ = self.get_action(batch_size, feed_dict, batch_loads, batch_sources, num_batch_sources, batch_source_weights, mode = 'greedy')\n","      action_str = ''.join(str(i) for i in action)\n","      throughput = self.envs[graph_idx].if_exist(action_str) \n","      if throughput != -1:\n","        print(\"evaluating graph {}, greedy placement\".format(graph_idx))\n","        print(\"action {} rank {}\".format(action_str, throughput/max_throughput))\n","      else:\n","        t = Task(batch_size, real_idx, action, None, False, self.hparams.placement_file+'_'+str(len(tasks))+'.json', self.hparams.cep_program, self.exp_folder)\n","        tasks.append(t)\n","\n","      if len(tasks) == 10:\n","        with Pool(10) as p:\n","          samples = p.map(evaluate, tasks)\n","          for s, t in zip(samples, tasks):\n","            r = s.throughput/self.envs[t.graph_idx].max_throughput\n","            self.envs[t.graph_idx].save_test(s.throughput, s.action_str)\n","            print(\"evaluating graph {}, greedy placement\".format(t.graph_idx))\n","            print(\"action {} rank {}\".format(s.action_str, r))\n","          tasks = []\n","    \n","    if len(tasks) > 0:  \n","      with Pool(min(10, len(tasks))) as p:\n","        samples = p.map(evaluate, tasks)\n","        for s, t in zip(samples, tasks):\n","          r = s.throughput/self.envs[t.graph_idx].max_throughput\n","          self.envs[t.graph_idx].save_test(s.throughput, s.action_str)\n","          print(\"evaluating graph {}, greedy placement\".format(t.graph_idx))\n","          print(\"action {} rank {}\".format(s.action_str, r))\n","        tasks = []\n","  \n","  def exec_no_fail(self,seq):\n","    p = Popen(seq, stdout=PIPE, stderr=PIPE)\n","    stdout, stderr = p.communicate()\n","    return stdout\n","  \n","  def uniform_action(self, num_ops, action):\n","    mapped_action = {}\n","    op_to_vm = {}\n","    vm_idx = 0\n","    for i in range(num_ops):\n","      vm = int(action[i])\n","      if vm not in mapped_action:\n","        mapped_action[vm] = vm_idx\n","        vm_idx += 1\n","      op_to_vm[int(i)] = mapped_action[vm]\n","    \n","    new_actions = []\n","    for op, vm in op_to_vm.items():\n","      new_actions.append(vm)\n","\n","    return new_actions\n","\n","  def calculate_utilization(self, action, batch_loads):\n","    device_utilization = []\n","    current_utilization = np.zeros((1, self.num_devices), dtype=float)\n","    for i in range(1):\n","      for j in range(self.num_devices):\n","        current_utilization[i, j] = self.hparams.utilization_max\n","    \n","    device_utilization.append(current_utilization)\n","    for idx, op in enumerate(batch_loads[:-1]):\n","      utilization = np.copy(current_utilization)\n","      utilization[0, action[idx]] -= batch_loads[idx]/1e6   \n","      device_utilization.append(utilization)\n","      current_utilization = utilization\n","    device_utilization = np.array(device_utilization)\n","    return device_utilization\n","\n","  def evaluate_cepsim(self, num_ops, graph_idx, action):\n","    configs = {}\n","    placements = []\n","    \n","    vm_placements = {}\n","    for i in range(num_ops):\n","      vm = int(action[i])\n","      if vm not in vm_placements:\n","        vm_placements[vm] = []\n","      vm_placements[vm].append(int(i))\n","    for vm, ops in vm_placements.items():\n","      placements.append({'idx':vm, 'ops': ops})\n","    configs['placements'] = placements\n","    \n","    used_vms = len(vm_placements)\n","    with open(self.hparams.placement_file, 'w') as outfile:\n","      json.dump(configs, outfile)\n","      outfile.flush()\n","      os.fsync(outfile.fileno())\n","      outfile.close()\n","    \n","    logs = self.exec_no_fail(['timeout', '-k','30s','-s', '9', '30s','java', 'ca.uwo.eng.sel.cepsim.example.'+self.hparams.cep_program, self.hparams.placement_file, self.exp_folder+'/graph_'+str(graph_idx)+'.json'])\n","    throughput = 0\n","    for line in logs.split(b'\\n'):\n","      if b\"Throughputs:\" in line:\n","        throughput += float(line.strip().split(b':')[1])\n","    return throughput/used_vms\n","    \n","  def save(self, epoch):\n","    save_path = self.saver.save(self.sess, self.hparams.checkpoint_folder + '/mode.'+str(epoch)+\".ckpt\")\n","    print(\"Model saved in path: %s\" % save_path)\n","    #store the environment as well\n","    with open(self.hparams.checkpoint_folder +'/' + str(epoch) + '.pkl', 'wb') as f:\n","      pickle.dump(self.envs, f, pickle.HIGHEST_PROTOCOL)\n","\n","  def construct_placeholders(self):\n","    placeholders = {\n","      'sample_size' : tf.placeholder(tf.int32, name='sample_size'),\n","      'num_samples' : tf.placeholder(tf.int32, name='num_samples'),\n","      'dropout' : tf.placeholder_with_default(0., shape=(), name='dropout'),\n","      'random_devices_logits' : tf.placeholder(tf.float32, shape=(None, None), name='random_devices_logits'),\n","      'reward' : tf.placeholder(tf.float32, shape=(None), name='reward'),\n","      'actions' : tf.placeholder(tf.int32, shape=(None, None),\n","      name='sample_actions'),\n","      'num_actions' : tf.placeholder(tf.int32, name = 'num_actions'),\n","      'batch' : tf.placeholder(tf.int32, shape=(None), name='batch1'),\n","      'batch_size' : tf.placeholder(tf.int32, name='batch_size'),\n","      'graph_idx' : tf.placeholder(tf.int32, name='graph_idx'),\n","      'batch_sources' : tf.placeholder(tf.int32, shape = (None, None), name = 'batch_sources'),\n","      'batch_num_sources' : tf.placeholder(tf.int32, shape = (None), name = 'batch_num_sources'),\n","      'batch_source_weights' : tf.placeholder(tf.float32, shape = (None, None), name = 'batch_source_weights'),\n","      'device_utilizations' : tf.placeholder(tf.float32, shape = (None, None, None), name = 'device_utilization'),\n","      'device_utilizations_forward' : tf.placeholder(tf.float32, shape = (None, None), name = 'device_utilization_forward'),\n","      'target_op': tf.placeholder(tf.int32, name = 'target_op'),\n","      'prev_y' : tf.placeholder(tf.int32, shape = (None), name = 'prev_y'),\n","      'prev_c' : tf.placeholder(tf.float32, shape = (None, None), name = 'prev_c'),\n","      'prev_h' : tf.placeholder(tf.float32, shape = (None, None), name = 'prev_h'),\n","      'source_weights' : tf.placeholder(tf.float32, shape = (None), name = 'source_weights'),\n","      'source_devices' : tf.placeholder(tf.int32, shape = (None, None), name = 'source_devices'),\n","      'node_sources_num' : tf.placeholder(tf.int32, name = 'node_sources_num'),\n","    }\n","    self.placeholders = placeholders\n","  \n","  def prepare_data(self):\n","    G, features, num_devices = load_ordered_folder_data(self.exp_folder)\n","    self.num_devices = self.hparams.num_devices\n","    #create Batch iterator with G and feats\n","    self.minibatch = GraphMinibatchIterator(G, self.placeholders, seed = self.hparams.seed, train_ratio = self.hparams.train_ratio, batch_size =\n","    self.hparams.env_batch_size, max_degree = self.hparams.max_degree)\n","    \n","    for idx, f in enumerate(features):\n","      features[idx] = np.vstack([f, np.zeros((f.shape[1],))])\n","    \n","    self.features = np.array(features) \n","\n","  def build_graph_model(self):\n","    sampler = UniformNeighborSampler(self.minibatch.adj_ins, self.minibatch.adj_outs)\n","    layer_infos = [SAGEInfo(\"node\", sampler, self.hparams.samples_1, self.hparams.dim_1),\n","                  SAGEInfo(\"node\", sampler, self.hparams.samples_2, self.hparams.dim_2)]\n","    if self.hparams.samples_3 != 0:\n","      layer_infos.append(SAGEInfo(\"node\", sampler, self.hparams.samples_3, self.hparams.dim_2))\n","      if self.hparams.samples_4 != 0:\n","        layer_infos.append(SAGEInfo(\"node\", sampler, self.hparams.samples_4, self.hparams.dim_2))\n","        if self.hparams.samples_5 != 0:\n","          layer_infos.append(SAGEInfo(\"node\", sampler, self.hparams.samples_5, self.hparams.dim_2))\n","          \n","    if self.hparams.graphsage_model == 'graphsage_mean':\n","      self.model = SupervisedGraphsage(self.placeholders, \n","                                     self.features,\n","                                     layer_infos, \n","                                     batch_size = self.hparams.env_batch_size, \n","                                     model_size=self.hparams.model_size,\n","                                     logging=True)\n","    \n","    elif self.hparams.graphsage_model == 'gcn':\n","      # Create model\n","      self.model = SupervisedGraphsage(self.placeholders, \n","                                   self.features,\n","                                   layer_infos, \n","                                   aggregator_type=\"gcn\",\n","                                   batch_size = self.hparams.env_batch_size, \n","                                   model_size=self.hparams.model_size,\n","                                   concat=False,\n","                                   logging=True)\n","\n","    elif self.hparams.graphsage_model == 'graphsage_seq':\n","      self.model = SupervisedGraphsage(self.placeholders, \n","                                   self.features,\n","                                   layer_infos, \n","                                   aggregator_type=\"seq\",\n","                                   model_size=self.hparams.model_size,\n","                                   batch_size = self.hparams.env_batch_size, \n","                                   logging=True)\n","\n","    elif self.hparams.graphsage_model == 'graphsage_maxpool':\n","      self.model = SupervisedGraphsage(self.placeholders, \n","                                   self.features,\n","                                   layer_infos, \n","                                   aggregator_type=\"maxpool\",\n","                                   model_size=self.hparams.model_size,\n","                                   batch_size = self.hparams.env_batch_size, \n","                                   logging=True)\n","\n","    elif self.hparams.graphsage_model == 'graphsage_meanpool':\n","      self.model = SupervisedGraphsage(self.placeholders, \n","                                  self.features,\n","                                  layer_infos, \n","                                   aggregator_type=\"meanpool\",\n","                                   model_size=self.hparams.model_size,\n","                                   batch_size = self.hparams.env_batch_size, \n","                                   logging=True)\n","\n","    else:\n","      raise Exception('Error: model name unrecognized.')\n","\n","    \n","    self.node_embeddings = self.model.get_node_preds()\n","    self.graph_embeddings = self.model.get_graph_preds()\n","\n","  def build_controller(self):\n","    self._global_step = tf.train.get_or_create_global_step()\n","    \n","    ctr = {}\n","    ctr[\"loss\"] = 0\n","\n","    actions = self.placeholders['actions']\n","    num_actions = self.placeholders['num_actions']\n","    reward = self.placeholders['reward']\n","    ctr[\"probs\"] = self.get_probs(actions, num_actions)\n","    \n","    ctr[\"loss\"] = tf.reduce_mean(reward * ctr[\"probs\"])\n","\n","    with tf.variable_scope(\n","        \"optimizer\", reuse=tf.AUTO_REUSE):\n","      (ctr[\"train_op\"], ctr[\"lr\"], ctr[\"grad_norm\"],\n","      ctr[\"grad_norms\"]) = self._get_train_ops(\n","           ctr[\"loss\"],\n","           tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES),\n","           self.global_step,\n","           grad_bound=self.hparams.grad_bound,\n","           lr_init=self.hparams.lr,\n","           lr_dec=self.hparams.lr_dec,\n","           start_decay_step=self.hparams.start_decay_step,\n","           decay_steps=self.hparams.decay_steps,\n","           optimizer_type=self.hparams.optimizer_type)\n","\n","    self.ctr = ctr\n","\n","  @property\n","  def global_step(self):\n","    return self._global_step\n","\n","  def build_generate_samples(self):\n","    if self.hparams.decoder == 'lstm':\n","      if self.hparams.embedding == 'graphsage':\n","        [random_action], [policy_action, policy_c, policy_h], [greedy_action, greedy_c, greedy_h] = self.build_graphsage_lstm_decoder()\n","      else:\n","        [random_action], [policy_action, policy_c, policy_h], [greedy_action, greedy_c, greedy_h] = self.build_original_lstm_decoder()\n","\n","      self.policy_action = policy_action\n","      self.greedy_action = greedy_action\n","      self.random_action = random_action\n","      self.greedy_c = greedy_c\n","      self.greedy_h = greedy_h\n","      self.policy_c = policy_c\n","      self.policy_h = policy_h\n","    else:\n","      raise NotImplementedError\n","\n","  def build_graphsage_lstm_decoder(self):\n","    ph = self.placeholders\n","    sample_size = ph[\"sample_size\"]\n","    random_devices_logits = ph[\"random_devices_logits\"]\n","    random_action = self.encode_forward_random(random_devices_logits)\n","    \n","    attn_mem = self.node_embeddings\n","    last_h = self.graph_embeddings\n","    attn_mem = tf.expand_dims(attn_mem, 0)\n","    attn_mem = tf.tile(attn_mem, [sample_size, 1, 1])\n","    last_h = tf.expand_dims(last_h, 0)\n","    last_h = tf.tile(last_h, [sample_size, 1, 1])\n","    last_h = tf.reshape(last_h, [sample_size, self.hparams.hidden_size])\n","    \n","    device_utilization = self.placeholders['device_utilizations_forward']\n","    target_op = self.placeholders['target_op']\n","    prev_c = self.placeholders['prev_c']\n","    prev_h = self.placeholders['prev_h']\n","    prev_y = self.placeholders['prev_y']\n","      \n","    num_ops = self.placeholders['batch_size']\n","    policy_action, policy_c, policy_h = (self.decode_forward(num_ops, target_op, sample_size, prev_c, prev_h, last_h, attn_mem, device_utilization, prev_y, mode=\"sample\"))\n","    greedy_action, greedy_c, greedy_h = (self.decode_forward(num_ops, target_op, sample_size, prev_c, prev_h, last_h, attn_mem, device_utilization, prev_y, mode=\"greedy\"))\n","    return [random_action], [policy_action, policy_c, policy_h], [greedy_action, greedy_c, greedy_h]\n","  \n","  def build_original_lstm_decoder(self):\n","    ph = self.placeholders\n","    sample_size = ph[\"sample_size\"]\n","    random_devices_logits = ph[\"random_devices_logits\"]\n","    g_id = ph[\"graph_idx\"]\n","    random_action = self.encode_forward_random(random_devices_logits)\n","\n","    self.features = tf.Variable(tf.constant(self.features, dtype=tf.float32), trainable=False)\n","    graph_idx = self.placeholders[\"graph_idx\"]\n","    input_features = tf.slice(self.features, [g_id, 0, 0], [1, -1, -1])\n","    input_features = tf.reshape(input_features, [self.features.shape[1], self.features.shape[2]])\n","    \n","    device_utilization = self.placeholders['device_utilizations_forward']\n","    target_op = self.placeholders['target_op']\n","    prev_c = self.placeholders['prev_c']\n","    prev_h = self.placeholders['prev_h']\n","    \n","    policy_action, policy_c, policy_h = (self.encode_forward(target_op, input_features, sample_size, prev_c, prev_h, device_utilization, mode='sample'))\n","    greedy_action, greedy_c, greedy_h = (self.encode_forward(target_op, input_features, sample_size, prev_c, prev_h, device_utilization, mode='greedy'))\n","    \n","    return [random_action], [policy_action, policy_c, policy_h], [greedy_action, greedy_c, greedy_h]\n","\n","\n","  def compute_probs(self, actions, num_actions, fd):\n","    feed_dict = dict()\n","    feed_dict.update({self.placeholders['num_actions'] : num_actions})\n","    feed_dict.update({self.placeholders['actions'] : actions})\n","    feed_dict.update({self.placeholders['batch'] : fd['batch']})\n","    feed_dict.update({self.placeholders['batch_sources'] : fd['batch_sources']})\n","    feed_dict.update({self.placeholders['batch_source_weights'] : fd['batch_source_weights']})\n","    feed_dict.update({self.placeholders['device_utilizations'] : fd['device_utilizations']})\n","    feed_dict.update({self.placeholders['batch_num_sources'] : fd['batch_num_sources']})\n","    feed_dict.update({self.placeholders['batch_size'] : fd['batch_size']})\n","    feed_dict.update({self.placeholders['graph_idx'] : fd['graph_idx']})\n","    probs = self.sess.run(self.ctr[\"probs\"], feed_dict=feed_dict)\n","    return [np.exp(-l) for l in probs]\n","\n","  def get_probs_graphsage_lstm(self, actions, num_actions):\n","    device_utilizations = self.placeholders['device_utilizations']\n","    attn_mem = self.node_embeddings\n","    last_h = self.graph_embeddings\n","    attn_mem = tf.expand_dims(attn_mem, 0)\n","    attn_mem = tf.tile(attn_mem, [num_actions, 1, 1])\n","    last_h = tf.expand_dims(last_h, 0)\n","    last_h = tf.tile(last_h, [num_actions, 1, 1])\n","    last_h = tf.reshape(last_h, [num_actions, self.hparams.hidden_size])\n","    \n","    num_ops = self.placeholders['batch_size']\n","    \n","    _, log_probs = (self.decode(num_ops, num_actions,\n","            last_h, attn_mem, device_utilizations, actions))\n","    \n","    return log_probs\n","  \n","  def get_probs_original_lstm(self, actions, num_actions):\n","    device_utilizations = self.placeholders['device_utilizations']\n","    num_ops = self.placeholders['batch_size']\n","    g_id = self.placeholders[\"graph_idx\"]\n","    input_features = tf.slice(self.features, [g_id, 0, 0], [1, -1, -1])\n","    input_features = tf.reshape(input_features, [self.features.shape[1], self.features.shape[2]])\n","    \n","    _, log_probs = (self.encode(input_features, num_ops, num_actions, device_utilizations, actions))\n","    \n","    return log_probs\n","\n","  def get_probs(self, actions, num_actions):\n","    if self.hparams.decoder == 'lstm':\n","      if self.hparams.embedding == 'graphsage':\n","        return self.get_probs_graphsage_lstm(actions, num_actions)\n","      elif self.hparams.embedding == 'original':\n","        return self.get_probs_original_lstm(actions, num_actions)\n","      else:\n","        raise NotImplementedError\n","  \n","  def aggregate_source_devices(self, i, actions, num_children, sources, node_sources_num, source_weights):\n","    with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","      device_aggregator = tf.get_variable(\"device_aggregator\")\n","    \n","    node_sources = tf.slice(sources, [i, 0], [1, node_sources_num])\n","    node_sources = tf.reshape(node_sources, [node_sources_num])\n","    if self.hparams.weighed_neighbor_placement:\n","      source_weights = tf.slice(source_weights, [i, 0], [1, node_sources_num])\n","      source_weights = tf.reshape(source_weights, [node_sources_num])\n","      source_weights = tf.expand_dims(source_weights, 0)\n","      source_weights = tf.tile(source_weights, [num_children, 1])\n","      source_weights = tf.reshape(source_weights, [num_children*node_sources_num, 1])\n","\n","    source_actions = tf.map_fn(lambda x:actions.read(x), node_sources)\n","    source_actions = tf.transpose(source_actions, [1, 0])\n","    source_actions = tf.reshape(source_actions, [node_sources_num * num_children])\n","    source_devices = tf.nn.embedding_lookup(self.device_encoding, source_actions)\n","    #\n","    source_devices = tf.reshape(source_devices, (node_sources_num * num_children, self.num_devices))\n","    if self.hparams.weighed_neighbor_placement:\n","      source_devices = source_weights  * source_devices\n","    source_devices_embeddings = tf.matmul(source_devices, device_aggregator)\n","    source_devices_embeddings = tf.reshape(source_devices_embeddings, [num_children, node_sources_num, self.hparams.hidden_size])\n","    if self.hparams.weighed_neighbor_placement:\n","      source_devices_embeddings = tf.reduce_sum(source_devices_embeddings, axis=1)\n","    else:\n","      source_devices_embeddings = tf.reduce_mean(source_devices_embeddings, axis=1)\n","    \n","    source_devices_embeddings = tf.reshape(source_devices_embeddings, [num_children, self.hparams.hidden_size])\n","    \n","    return source_devices_embeddings\n","  \n","  def aggregate_source_devices_forward(self, num_children, source_devices, source_weights, node_sources_num):\n","    with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","      device_aggregator = tf.get_variable(\"device_aggregator\")\n","    \n","    source_devices = tf.reshape(source_devices, [num_children*node_sources_num, 1])\n","    source_devices = tf.nn.embedding_lookup(self.device_encoding, source_devices)\n","    \n","    source_devices = tf.reshape(source_devices, (node_sources_num * num_children, self.num_devices))\n","    if self.hparams.weighed_neighbor_placement:\n","      source_weights = tf.expand_dims(source_weights, 0)\n","      source_weights = tf.tile(source_weights, [num_children, 1])\n","      source_weights = tf.reshape(source_weights, [num_children*node_sources_num, 1])\n","      source_devices = source_weights  * source_devices\n","    source_devices_embeddings = tf.matmul(source_devices, device_aggregator)\n","    source_devices_embeddings = tf.reshape(source_devices_embeddings, [num_children, node_sources_num, self.hparams.hidden_size])\n","    if self.hparams.weighed_neighbor_placement:\n","      source_devices_embeddings = tf.reduce_sum(source_devices_embeddings, axis=1)\n","    else:\n","      source_devices_embeddings = tf.reduce_mean(source_devices_embeddings, axis=1)\n","    \n","    source_devices_embeddings = tf.reshape(source_devices_embeddings, [num_children, self.hparams.hidden_size])\n","    return source_devices_embeddings\n","  \n","  def decode_forward(self, num_ops, target_op, num_children, prev_c, prev_h, last_h, attn_mem, device_utilizations, prev_y, mode = 'sample'):\n","    h = tf.cond(tf.equal(target_op, 0),\n","        lambda: last_h,\n","        lambda: prev_h)\n","    ph = self.placeholders\n","    \n","    num_samples = self.placeholders['num_samples']\n","\n","    with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","      w_lstm = tf.get_variable(\"decoder_lstm\")\n","      forget_bias = tf.get_variable(\"decoder_forget_bias\")\n","      device_embeddings = tf.get_variable(\"device_embeddings\")\n","      device_softmax = tf.get_variable(\"device_softmax\")\n","     \n","      device_go_embedding = tf.get_variable(\"device_go_embedding\")\n","      attn_w_2 = tf.get_variable(\"attn_w_2\")\n","      attn_v = tf.get_variable(\"attn_v\")\n","    \n","    attn = tf.slice(self.node_embeddings, [target_op, 0], [1, -1])\n","    attn = tf.reshape(attn, [1, self.hparams.hidden_size])\n","    attn = tf.expand_dims(attn, 0)\n","    attn = tf.tile(attn, [num_children, 1, 1])\n","    attn = tf.reshape(attn, [num_children, self.hparams.hidden_size])\n","        \n","    signal = attn\n","    \n","    if self.hparams.consider_neighbor_placement:\n","      node_sources_num = self.placeholders['node_sources_num']\n","      source_devices = self.placeholders['source_devices']\n","      source_weights = self.placeholders['source_weights']\n","      source_devices_embeddings = tf.cond(tf.equal(node_sources_num, 0), lambda: tf.zeros([num_children, self.hparams.hidden_size], dtype=tf.float32), lambda: self.aggregate_source_devices_forward(num_children, source_devices, source_weights, node_sources_num))\n","      signal = tf.concat([signal, source_devices_embeddings], axis = 1)\n","    \n","    next_c, next_h = lstm(signal, prev_c, h, w_lstm, forget_bias)\n","    query = tf.matmul(next_h, attn_w_2)\n","    query = tf.reshape(query, [num_children, 1, self.hparams.hidden_size])\n","    query = tf.tanh(query + attn_mem)\n","    query = tf.reshape(query, [num_children * num_ops, self.hparams.hidden_size])\n","    query = tf.matmul(query, attn_v)\n","    query = tf.reshape(query, [num_children, num_ops])\n","    query = tf.nn.softmax(query)\n","    query = tf.reshape(query, [num_children, num_ops, 1])\n","    query = tf.reduce_sum(attn_mem * query, axis=1)\n","    query = tf.concat([next_h, query], axis=1)\n","    logits = tf.matmul(query, device_softmax)\n","    \n","    if self.hparams.consider_device_utilization:\n","      if self.hparams.device_scheme == 0:\n","        with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","          w_utilization = tf.get_variable(\"device_utilization\")\n","        logits = tf.concat([logits, device_utilizations], axis = 1)\n","        logits = tf.matmul(logits, w_utilization)\n","      else:\n","        logits = tf.nn.softmax(logits)\n","        logits = logits * device_utilizations\n","        logits = tf.log(logits)\n","\n","    if mode == \"sample\":\n","      next_y = tf.multinomial(logits, 1, seed=self.hparams.seed)\n","    elif mode == \"greedy\":\n","      next_y = tf.argmax(logits, 1)\n","    else:\n","      raise NotImplementedError\n","        \n","    next_y = tf.to_int32(next_y)\n","    next_y = tf.reshape(next_y, [num_children])\n","    return next_y, next_c, next_h\n","  \n","  #used for back propogation\n","  def decode(self,\n","             num_ops,\n","             num_children,\n","             last_h,\n","             attn_mem,\n","             device_utilizations, \n","             y):\n","    ph = self.placeholders\n","    sources = ph[\"batch_sources\"]\n","    num_sources = ph[\"batch_num_sources\"]\n","    source_weights = ph[\"batch_source_weights\"]\n","\n","    with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","      w_lstm = tf.get_variable(\"decoder_lstm\")\n","      forget_bias = tf.get_variable(\"decoder_forget_bias\")\n","      device_embeddings = tf.get_variable(\"device_embeddings\")\n","      device_softmax = tf.get_variable(\"device_softmax\")\n","     \n","      device_go_embedding = tf.get_variable(\"device_go_embedding\")\n","      attn_w_2 = tf.get_variable(\"attn_w_2\")\n","      attn_v = tf.get_variable(\"attn_v\")\n","    \n","    actions = tensor_array_ops.TensorArray(\n","        tf.int32,\n","        size=num_ops,\n","        infer_shape=False,\n","        clear_after_read=False)\n","    \n","    def condition(i, *args):\n","      return tf.less(i, num_ops)\n","\n","    def body(i, prev_c, prev_h, actions, log_probs):\n","      attn = tf.slice(self.node_embeddings, [i, 0], [1, -1])\n","      attn = tf.reshape(attn, [1, self.hparams.hidden_size])\n","      attn = tf.expand_dims(attn, 0)\n","      attn = tf.tile(attn, [num_children, 1, 1])\n","      attn = tf.reshape(attn, [num_children, self.hparams.hidden_size])\n","      \n","      signal = attn\n","      if self.hparams.consider_neighbor_placement:\n","        node_sources_num = tf.gather(num_sources, i)\n","        source_devices_embeddings = tf.cond(tf.equal(node_sources_num, 0), lambda: tf.zeros([num_children, self.hparams.hidden_size], dtype=tf.float32), lambda: self.aggregate_source_devices(i, actions, num_children, sources, node_sources_num, source_weights))\n","        signal = tf.concat([signal, source_devices_embeddings], axis = 1)\n","      next_c, next_h = lstm(signal, prev_c, prev_h, w_lstm, forget_bias)\n","      query = tf.matmul(next_h, attn_w_2)\n","      query = tf.reshape(\n","          query, [num_children, 1, self.hparams.hidden_size])\n","      query = tf.tanh(query + attn_mem)\n","      query = tf.reshape(query, [\n","          num_children * num_ops, self.hparams.hidden_size\n","      ])\n","      query = tf.matmul(query, attn_v)\n","      query = tf.reshape(query, [num_children, num_ops])\n","      query = tf.nn.softmax(query)\n","      query = tf.reshape(query, [num_children, num_ops, 1])\n","      query = tf.reduce_sum(attn_mem * query, axis=1)\n","      query = tf.concat([next_h, query], axis=1)\n","      logits = tf.matmul(query, device_softmax)\n","      if self.hparams.consider_device_utilization:\n","        utilization = tf.slice(device_utilizations, [i, 0, 0], [1, -1, -1])\n","        utilization = tf.reshape(utilization, [num_children, self.num_devices])\n","        if self.hparams.device_scheme == 0:\n","          logits = tf.concat([logits, utilization], axis = 1)\n","          with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","            w_utilization = tf.get_variable(\"device_utilization\")\n","          logits = tf.matmul(logits, w_utilization)\n","        else:\n","          logits = tf.nn.softmax(logits)\n","          logits = logits * utilization\n","          logits = tf.log(logits)\n","\n","      next_y = tf.slice(y, [0, i], [-1, 1])\n","        \n","      next_y = tf.to_int32(next_y)\n","      next_y = tf.reshape(next_y, [num_children])\n","      actions = actions.write(i, next_y)\n","      log_probs += tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=next_y)\n","      return i + 1, next_c, next_h, actions, log_probs\n","\n","    last_c = tf.zeros(\n","        [num_children, self.hparams.hidden_size],\n","        dtype=tf.float32)\n","    \n","    loop_vars = [tf.constant(0, dtype=tf.int32), last_c, last_h, actions,\n","        tf.zeros([num_children], dtype=tf.float32)]\n","\n","    loop_outputs = tf.while_loop(condition, body, loop_vars)\n","    \n","    last_c = loop_outputs[-4]\n","    last_h = loop_outputs[-3]\n","    actions = loop_outputs[-2].stack()\n","    actions = tf.transpose(actions, [1, 0])\n","    log_probs = loop_outputs[-1]\n","    return actions, log_probs\n","  \n","  def encode_forward_random(self, random_logits):\n","    next_y = tf.multinomial(random_logits, 1, seed=self.hparams.seed)\n","    next_y = tf.to_int32(next_y)\n","    next_y = tf.reshape(next_y, [1]) #only generate one random action at a time\n","    return next_y\n","\n","  def encode_forward(self, target_op, input_features, num_children, prev_c, prev_h, device_utilization, mode = \"sample\"):\n","    ph = self.placeholders\n","\n","    with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","      w_lstm = tf.get_variable(\"decoder_lstm\")\n","      forget_bias = tf.get_variable(\"decoder_forget_bias\")\n","      device_softmax = tf.get_variable(\"device_softmax\")\n","      node_embedding = tf.get_variable(\"node_embedding\")\n","      w_utilization = tf.get_variable(\"device_utilization\")\n","    \n","    signal = tf.slice(input_features, [target_op, 0], [1, -1])\n","    signal = tf.reshape(signal, [self.hparams.feat_size])\n","    signal = tf.expand_dims(signal, 0)\n","    signal = tf.tile(signal, [num_children, 1])\n","    signal = tf.reshape(signal, [num_children, self.hparams.feat_size])\n","    \n","    if self.hparams.keep_prob is not None:\n","      signal = tf.nn.dropout(signal, self.hparams.keep_prob)\n","    \n","    feature_embedding = tf.matmul(signal, node_embedding)\n","    if self.hparams.consider_device_utilization:\n","      utilization_embedding = tf.matmul(device_utilization, w_utilization)\n","      feature_embedding = tf.concat([feature_embedding, utilization_embedding], axis = 1)\n","    if self.hparams.consider_neighbor_placement:\n","      node_sources_num = self.placeholders['node_sources_num']\n","      source_devices = self.placeholders['source_devices']\n","      source_weights = self.placeholders['source_weights']\n","      source_devices_embeddings = tf.cond(tf.equal(node_sources_num, 0), lambda: tf.zeros([num_children, self.hparams.hidden_size], dtype=tf.float32), lambda: self.aggregate_source_devices_forward(num_children, source_devices, source_weights, node_sources_num))\n","      feature_embedding = tf.concat([feature_embedding, source_devices_embeddings], axis=1)\n","    \n","    next_c, next_h = lstm(feature_embedding, prev_c, prev_h, w_lstm, forget_bias)\n","    logits = tf.matmul(next_h, device_softmax)\n","    \n","    if mode == \"sample\":\n","      next_y = tf.multinomial(logits, 1, seed=self.hparams.seed)\n","    elif mode == \"greedy\":\n","      next_y = tf.argmax(logits, 1)\n","    else:\n","      raise NotImplementedError\n","    \n","    next_y = tf.to_int32(next_y)\n","    next_y = tf.reshape(next_y, [num_children])\n","    return next_y, next_c, next_h\n","\n","  def encode(self, input_features, num_ops, num_children, device_utilization, y):\n","    ph = self.placeholders\n","    sources = ph[\"batch_sources\"]\n","    num_sources = ph[\"batch_num_sources\"]\n","    source_weights = ph[\"batch_source_weights\"]\n","\n","    with tf.variable_scope(self.hparams.name, reuse=tf.AUTO_REUSE):\n","      w_lstm = tf.get_variable(\"decoder_lstm\")\n","      forget_bias = tf.get_variable(\"decoder_forget_bias\")\n","      device_softmax = tf.get_variable(\"device_softmax\")\n","      node_embedding = tf.get_variable(\"node_embedding\")\n","      w_utilization = tf.get_variable(\"device_utilization\")\n","\n","    actions = tensor_array_ops.TensorArray(\n","        tf.int32,\n","        size=num_ops,\n","        infer_shape=False,\n","        clear_after_read=False)\n","    \n","    def condition(i, *args):\n","      return tf.less(i, num_ops)\n","\n","    def body(i, prev_c, prev_h, actions, log_probs):\n","      signal = tf.slice(input_features, [i, 0], [1, -1])\n","      signal = tf.reshape(signal, [self.hparams.feat_size])\n","      signal = tf.expand_dims(signal, 0)\n","      signal = tf.tile(signal, [num_children, 1])\n","      signal = tf.reshape(signal, [num_children, self.hparams.feat_size])\n","      \n","      if self.hparams.keep_prob is not None:\n","        signal = tf.nn.dropout(signal, self.hparams.keep_prob)\n","      feature_embedding = tf.matmul(signal, node_embedding)\n","      \n","      if self.hparams.consider_device_utilization:\n","        utilization = tf.slice(device_utilization, [i, 0, 0], [1, -1, -1])\n","        utilization = tf.reshape(utilization, [num_children, self.num_devices])\n","        utilization_embedding = tf.matmul(utilization, w_utilization)\n","        feature_embedding = tf.concat([feature_embedding, utilization_embedding], axis = 1)\n","      if self.hparams.consider_neighbor_placement:\n","        node_sources_num = tf.gather(num_sources, i)\n","        source_devices_embeddings = tf.cond(tf.equal(node_sources_num, 0), lambda: tf.zeros([num_children, self.hparams.hidden_size], dtype=tf.float32), lambda: self.aggregate_source_devices(i, actions, num_children, sources, node_sources_num, source_weights))\n","        feature_embedding = tf.concat([feature_embedding, source_devices_embeddings], axis = 1)\n","      next_c, next_h = lstm(feature_embedding, prev_c, prev_h, w_lstm, forget_bias)\n","      logits = tf.matmul(next_h, device_softmax)\n","      \n","      next_y = tf.slice(y, [0, i], [-1, 1])\n","      \n","      next_y = tf.to_int32(next_y)\n","      next_y = tf.reshape(next_y, [num_children])\n","      actions = actions.write(i, next_y)\n","      log_probs += tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=next_y)\n","      return i + 1, next_c, next_h, actions, log_probs\n","\n","    last_c = tf.zeros(\n","          [num_children, self.hparams.hidden_size],\n","          dtype=tf.float32)\n","    last_h = tf.zeros(\n","          [num_children, self.hparams.hidden_size],\n","          dtype=tf.float32)\n","    \n","    loop_vars = [tf.constant(0, dtype=tf.int32), last_c, last_h, actions,\n","        tf.zeros([num_children], dtype=tf.float32)]\n","\n","    loop_outputs = tf.while_loop(condition, body, loop_vars)\n","    \n","    last_c = loop_outputs[-4]\n","    last_h = loop_outputs[-3]\n","    actions = loop_outputs[-2].stack()\n","    actions = tf.transpose(actions, [1, 0])\n","    log_probs = loop_outputs[-1]\n","    return actions, log_probs\n","\n","  def optimize(self, fd):\n","    feed_dict = dict()\n","\n","    feed_dict.update({self.placeholders['num_actions'] : fd['num_actions']})\n","    feed_dict.update({self.placeholders['actions'] : fd['actions']})\n","    feed_dict.update({self.placeholders['reward'] : fd['reward']})\n","    feed_dict.update({self.placeholders['batch'] : fd['batch']})\n","    feed_dict.update({self.placeholders['batch_sources'] : fd['batch_sources']})\n","    feed_dict.update({self.placeholders['batch_num_sources'] : fd['batch_num_sources']})\n","    feed_dict.update({self.placeholders['batch_size'] : fd['batch_size']})\n","    feed_dict.update({self.placeholders['graph_idx'] : fd['graph_idx']})\n","    feed_dict.update({self.placeholders['device_utilizations'] : fd['device_utilizations']})\n","    feed_dict.update({self.placeholders['batch_source_weights'] : fd['batch_source_weights']})\n","    \n","    controller_ops = self.ctr\n","    \n","    run_ops = [controller_ops[\"probs\"], \n","        controller_ops[\"loss\"], controller_ops[\"lr\"],\n","        controller_ops[\"grad_norm\"], controller_ops[\"grad_norms\"],\n","        controller_ops[\"train_op\"]\n","    ]\n","    probs, loss, _, _, _, _ = self.sess.run(run_ops, feed_dict=feed_dict)\n","\n","  def _get_train_ops(self,\n","                     loss,\n","                     tf_variables,\n","                     global_step,\n","                     grad_bound=1.25,\n","                     lr_init=1e-3,\n","                     lr_dec=0.9,\n","                     start_decay_step=10000,\n","                     decay_steps=100,\n","                     optimizer_type=\"adam\"):\n","    def f1():\n","      return tf.constant(lr_init)\n","\n","    def f2():\n","      return tf.train.exponential_decay(lr_init, lr_gstep, decay_steps, lr_dec, True)\n","\n","    learning_rate = tf.cond(\n","        tf.less(global_step, start_decay_step),\n","        f1,\n","        f2,\n","        name=\"learning_rate\")\n","\n","    if optimizer_type == \"adam\":\n","      opt = tf.train.AdamOptimizer(learning_rate)\n","    elif optimizer_type == \"sgd\":\n","      opt = tf.train.GradientDescentOptimizer(learning_rate)\n","    grads_and_vars = opt.compute_gradients(loss, tf_variables)\n","    grad_norm = tf.global_norm([g for g, v in grads_and_vars])\n","    all_grad_norms = {}\n","    clipped_grads = []\n","    clipped_rate = tf.maximum(grad_norm / grad_bound, 1.0)\n","    for g, v in grads_and_vars:\n","      if g is not None:\n","        if isinstance(g, tf.IndexedSlices):\n","          clipped = g.values / clipped_rate\n","          norm_square = tf.reduce_sum(clipped * clipped)\n","          clipped = tf.IndexedSlices(clipped, g.indices)\n","        else:\n","          clipped = g / clipped_rate\n","          norm_square = tf.reduce_sum(clipped * clipped)\n","        all_grad_norms[v.name] = tf.sqrt(norm_square)\n","        clipped_grads.append((clipped, v))\n","\n","    train_op = opt.apply_gradients(clipped_grads, global_step)\n","    return train_op, learning_rate, grad_norm, all_grad_norms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUiHo84LN8_s","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1621895450758,"user_tz":420,"elapsed":24,"user":{"displayName":"Aditya Mamidi","photoUrl":"https://lh3.googleusercontent.com/-ZVjFvZzfSRk/AAAAAAAAAAI/AAAAAAAAO_o/YuKurwGqPLs/s64/photo.jpg","userId":"11230502904851788584"}},"outputId":"553784ac-1e49-462e-b71d-19703c618602"},"source":["hpara = allocator_hparams()\n","# hpara.add_param('embedding', 'original')\n","# print(hpara.embedding)\n","ra = ResourceAllocator(hpara, exp_folder = 'dataset_small')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-3963482ceefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhpara\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallocator_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# hpara.add_param('embedding', 'original')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(hpara.embedding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResourceAllocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpara\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dataset_small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'allocator_hparams' is not defined"]}]},{"cell_type":"code","metadata":{"id":"5a4JaFaU2lOf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d51b4dbc-49e5-4b4c-90b3-4ea4de257424"},"source":["!python controller_device.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From controller_device.py:639: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From controller_device.py:641: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","/content/drive/My Drive/Classwork/CSE_257/DREAM/graphsage/utils.py:168: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  feats = np.vstack(_ for _ in all_feats)\n","processing graph 0 id 0\n","processing graph 1 id 1\n","processing graph 2 id 2\n","processing graph 3 id 3\n","processing graph 4 id 4\n","processing graph 5 id 5\n","processing graph 6 id 6\n","processing graph 7 id 7\n","processing graph 8 id 8\n","processing graph 9 id 9\n","[2, 9, 6, 4, 0, 3, 1, 7]\n","(10, 5, 2)\n","[2, 128, 128]\n","WARNING:tensorflow:From /content/drive/My Drive/Classwork/CSE_257/DREAM/graphsage/layers.py:93: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Classwork/CSE_257/DREAM/graphsage/layers.py:94: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Classwork/CSE_257/DREAM/graphsage/inits.py:18: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","max pooling dimension 2 and 128, True\n","max pooling dimension 256 and 128, True\n","max pooling graph dimension 512 and 512\n","WARNING:tensorflow:From /content/drive/My Drive/Classwork/CSE_257/DREAM/graphsage/neigh_samplers.py:34: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Classwork/CSE_257/DREAM/graphsage/layers.py:107: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From controller_device.py:211: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:From controller_device.py:1110: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","WARNING:tensorflow:From controller_device.py:1111: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From controller_device.py:742: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From controller_device.py:759: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From controller_device.py:759: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From controller_device.py:1268: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n","\n","WARNING:tensorflow:From controller_device.py:1277: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From controller_device.py:1281: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n","\n","WARNING:tensorflow:From controller_device.py:247: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2021-05-25 08:12:30.620575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-05-25 08:12:30.703367: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-05-25 08:12:30.703457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (36753a0d5f54): /proc/driver/nvidia/version does not exist\n","2021-05-25 08:12:30.737355: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n","2021-05-25 08:12:30.738251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a2d28b0f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-05-25 08:12:30.738347: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","WARNING:tensorflow:From controller_device.py:253: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From controller_device.py:254: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n","\n","WARNING:tensorflow:From controller_device.py:255: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","start epoch 0 1621930351.325123\n","*******************\n","*******************\n","evaluating graph 5, greedy placement\n","action 0000 rank 0.0\n","evaluating graph 8, greedy placement\n","action 0000 rank 0.0\n","Model saved in path: checkpoints/mode.0.ckpt\n","start epoch 1 1621930361.1065238\n","evaluating graph 5, greedy placement\n","action 0000 rank 0.0\n","evaluating graph 8, greedy placement\n","action 0000 rank 0.0\n","start epoch 2 1621930370.1385622\n","evaluating graph 5, greedy placement\n","action 0000 rank 0.0\n","evaluating graph 8, greedy placement\n","action 0000 rank 0.0\n","start epoch 3 1621930379.161436\n","evaluating graph 5, greedy placement\n","action 0000 rank 0.0\n","evaluating graph 8, greedy placement\n","action 0000 rank 0.0\n","start epoch 4 1621930388.335596\n","evaluating graph 5, greedy placement\n","action 0000 rank 0.0\n","evaluating graph 8, greedy placement\n","action 0000 rank 0.0\n","start epoch 5 1621930397.6902041\n","evaluating graph 5, greedy placement\n","action 0000 rank 0.0\n","evaluating graph 8, greedy placement\n","action 0000 rank 0.0\n","start epoch 6 1621930406.9671996\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OVLwOkbqlPVJ"},"source":[""],"execution_count":null,"outputs":[]}]}